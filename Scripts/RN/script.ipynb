{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\r\n",
    "import re\r\n",
    "\r\n",
    "import datetime\r\n",
    "\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from urllib.request import urlopen\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_pdf_link(date):\r\n",
    "    try:\r\n",
    "        url = urlopen(\r\n",
    "            'http://www.saude.rn.gov.br/Conteudo.asp?TRAN=ITEM&TARG=240728&ACT=&PAGE=0&PARM=&LBL=ACERVO+DE+MAT%C9RIAS')\r\n",
    "    except Exception as e:\r\n",
    "        print(e)\r\n",
    "\r\n",
    "    soup = BeautifulSoup(url.read(), \"html.parser\")\r\n",
    "    url.close()\r\n",
    "\r\n",
    "    url_pdf_link = soup.find_all(\"div\", {\"id\": \"P000\"})[0].find_all(\"ul\")\r\n",
    "\r\n",
    "    pattern = r\"\\d{2}\\/\\d{2}\\/\\d{4}\"\r\n",
    "    for el in url_pdf_link:\r\n",
    "        for li in el.find_all(\"li\"):\r\n",
    "            try:\r\n",
    "                li_date = re.findall(pattern, str(li), re.MULTILINE)[0]\r\n",
    "                if li_date == date:\r\n",
    "                    return li.find_all(\"a\")[0][\"href\"]\r\n",
    "            except IndexError:\r\n",
    "                pass\r\n",
    "    print(f\"{date} Data informada não econtrada na lista de pdfs.\"\r\n",
    "          \"*Considere que o estado não gera relátorios nos finais de semana. \\n\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_table(data_frame):\r\n",
    "    def format_row(data_frame, column):\r\n",
    "        for i in range(len(data_frame[column])):\r\n",
    "            row = data_frame.at[i, column]\r\n",
    "            if len(row.split(\" \")) > 1:\r\n",
    "                data_frame.at[i, column] = row.split(\" \")[0]\r\n",
    "\r\n",
    "    data_frame.replace('\\n', '', regex=True, inplace=True)\r\n",
    "\r\n",
    "    # Fix columns names\r\n",
    "    for col in range(len(list(data_frame))):\r\n",
    "        col_name = data_frame.get(col)[0] if data_frame.get(col)[\r\n",
    "            0] != \"\" else data_frame.get(col)[1]\r\n",
    "        data_frame.rename(columns={col: col_name}, inplace=True)\r\n",
    "\r\n",
    "    # Drop unecessary rows, reset index to start by 0, get only necessary columns rename columns with Brasil.io pattern\r\n",
    "    data_frame = data_frame.drop([0, 1]).reset_index(drop=True)[[\"MUNICÍPIO DE RESIDÊNCIA\", \"CASOS CONFIRMADOS\", \"ÓBITOS CONFIRMADOS\"]].rename(\r\n",
    "        columns={\"MUNICÍPIO DE RESIDÊNCIA\": \"municipio\", \"CASOS CONFIRMADOS\": \"confirmados\", \"ÓBITOS CONFIRMADOS\": \"mortes\"})\r\n",
    "\r\n",
    "    # Change specific city name when occurs\r\n",
    "    if 'AUGUSTO SEVERO (CAMPO GRANDE)' in data_frame.municipio.values:\r\n",
    "        data_frame.replace(\"AUGUSTO SEVERO (CAMPO GRANDE)\",\r\n",
    "                           \"CAMPO GRANDE\", inplace=True)\r\n",
    "    elif 'JANUÁRIO CICCO (BOA SAÚDE)' in data_frame.municipio.values:\r\n",
    "        data_frame.replace(\"JANUÁRIO CICCO (BOA SAÚDE)\",\r\n",
    "                           \"JANUÁRIO CICCO\", inplace=True)\r\n",
    "    data_frame[\"municipio\"] = data_frame[\"municipio\"].str.title()\r\n",
    "\r\n",
    "    # if two values in the same row, get first value\r\n",
    "    format_row(data_frame, \"confirmados\")\r\n",
    "    format_row(data_frame, \"mortes\")\r\n",
    "\r\n",
    "    return data_frame\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_row(data_frame, name_row, t_confirmado, t_obito):\r\n",
    "    data_frame.loc[-1] = [name_row, t_confirmado, t_obito]  # adding a row\r\n",
    "    data_frame.index = data_frame.index + 1  # shifting index\r\n",
    "    return data_frame.sort_index()  # sorting by index\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_values(val, val_local, val_gov):\r\n",
    "    return int(val) + int(val_local) == int(val_gov)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RN_2021-06-28.csv Gerado \n",
      " - Coonfirmados retornou valores diferentes: (337294, 0) \n",
      " - Mortes retornou valores diferentes: (6748, 0) \n",
      "\n",
      "Script ended\n"
     ]
    }
   ],
   "source": [
    "# Dates to generate csvs\r\n",
    "dates = [\"2021-06-28\"]\r\n",
    "\r\n",
    "for date in dates:\r\n",
    "    # Date + one day to get correct data\r\n",
    "    new_date = (datetime.datetime.strptime(date, \"%Y-%m-%d\") +\r\n",
    "            datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\r\n",
    "\r\n",
    "    url_pdf = date_to_pdf_link(f\"{new_date[8:10]}/{new_date[5:7]}/{new_date[:4]}\")\r\n",
    "\r\n",
    "    # Generate tables from url\r\n",
    "    try:\r\n",
    "        tables = camelot.read_pdf(url_pdf, pages=\"all\")\r\n",
    "    except AttributeError:\r\n",
    "        tables = None\r\n",
    "\r\n",
    "    if (tables):\r\n",
    "        # Iterate all tables\r\n",
    "        for i in range(len(tables)):\r\n",
    "            table = tables[i].df\r\n",
    "            if table.at[0, 0] == 'MUNICÍPIO DE RESIDÊNCIA':\r\n",
    "                if not ('data_frame' in vars() or 'data_frame' in globals()):\r\n",
    "                    data_frame = format_table(table)\r\n",
    "                else:\r\n",
    "                    try:\r\n",
    "                        data_frame = data_frame.append(\r\n",
    "                            format_table(table), ignore_index=True)\r\n",
    "                    except Exception as e:\r\n",
    "                        print(e)\r\n",
    "\r\n",
    "        # Getting total numbers\r\n",
    "        penultimate_row_df = data_frame.iloc[-2].name\r\n",
    "        last_row_df = data_frame.iloc[-1].name\r\n",
    "\r\n",
    "        total_conf_import_local = 0\r\n",
    "        total_death_import_local = 0\r\n",
    "        total_conf_gov = 0\r\n",
    "        total_death_gov = 0\r\n",
    "        if ((data_frame.at[penultimate_row_df, \"municipio\"] == \"Outras Localidades\") and\r\n",
    "                (data_frame.at[last_row_df, \"municipio\"] == \"Total Geral\")):\r\n",
    "            total_conf_import_local = data_frame.at[penultimate_row_df, \"confirmados\"].replace(\r\n",
    "                \".\", \"\")\r\n",
    "            total_death_import_local = data_frame.at[penultimate_row_df, \"mortes\"].replace(\r\n",
    "                \".\", \"\")\r\n",
    "            total_conf_gov = data_frame.at[last_row_df,\r\n",
    "                                           \"confirmados\"].replace(\".\", \"\")\r\n",
    "            total_death_gov = data_frame.at[last_row_df, \"mortes\"].replace(\r\n",
    "                \".\", \"\")\r\n",
    "            # Remove unecessary 3 last lines\r\n",
    "            data_frame.drop(data_frame.tail(3).index, inplace=True)\r\n",
    "        else:\r\n",
    "            # Remove unecessary last line\r\n",
    "            data_frame.drop(data_frame.tail(1).index, inplace=True)\r\n",
    "\r\n",
    "        # Sum total numbers\r\n",
    "        total_conf = data_frame[\"confirmados\"].astype(float).sum()\r\n",
    "        total_morte = data_frame[\"mortes\"].astype(float).sum()\r\n",
    "\r\n",
    "        # Compare sum totals with gov totals\r\n",
    "        result_total = compare_values(\r\n",
    "            total_conf, total_conf_import_local, total_conf_gov)\r\n",
    "        result_morte = compare_values(\r\n",
    "            total_morte, total_death_import_local, total_death_gov)\r\n",
    "\r\n",
    "        # Generate file name\r\n",
    "        file_name = 'RN_%s.csv' % date\r\n",
    "\r\n",
    "        # Adding new row to data_frame with total numbers\r\n",
    "        data_frame = add_new_row(data_frame, \"Importados/Indefinidos\",\r\n",
    "                                 total_conf_import_local, total_death_import_local)\r\n",
    "        data_frame = add_new_row(data_frame, \"TOTAL NO ESTADO\", int(\r\n",
    "            total_conf) + int(total_conf_import_local), int(total_morte) + int(total_death_import_local))\r\n",
    "        # Generate csv\r\n",
    "        data_frame.to_csv(file_name, line_terminator=None, index=False)\r\n",
    "\r\n",
    "        # Add values and generate csv if compared values are equals\r\n",
    "        if (result_total and result_morte):\r\n",
    "            print(file_name, \"Gerado\")\r\n",
    "        else:\r\n",
    "            result_text = f\"{file_name} Gerado \\n\"\r\n",
    "            if result_total != True:\r\n",
    "                result_text += f\" - Coonfirmados retornou valores diferentes:\" \\\r\n",
    "                    f\" {int(total_conf) + int(total_conf_import_local), int(total_conf_gov)} \\n\"\r\n",
    "            if result_total != True:\r\n",
    "                result_text += f\" - Mortes retornou valores diferentes:\" \\\r\n",
    "                    f\" {int(total_morte) + int(total_death_import_local), int(total_death_gov)} \\n\"\r\n",
    "            print(result_text)\r\n",
    "\r\n",
    "        # Delete var for next iterations\r\n",
    "        del(data_frame)\r\n",
    "print(\"Script ended\")\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c3b4f3a3e2c3e8780cfee43d81b915f3aa66dace7bef9eda32c5a7dd9110afb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('webscreaping_venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "1c3b4f3a3e2c3e8780cfee43d81b915f3aa66dace7bef9eda32c5a7dd9110afb"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}