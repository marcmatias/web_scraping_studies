{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import openpyxl\n",
    "import datetime\n",
    "\n",
    "from io import BytesIO\n",
    "import urllib\n",
    "\n",
    "# importing pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Pdf checker\n",
    "import re\n",
    "import pdfplumber\n",
    "\n",
    "import requests\n",
    "\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_values_pdf(date):\n",
    "    # Getting url link for pdf in official page\n",
    "    url = 'https://coronavirus.saude.mg.gov.br/boletim'\n",
    "    u = urlopen(url)\n",
    "    try:\n",
    "        html = u.read().decode('utf-8')\n",
    "    finally:\n",
    "        u.close()\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    url_pdf_link = soup.find('a', string=lambda value: value and value.endswith(date))[\"href\"]\n",
    "\n",
    "    # Request and Open PDF file\n",
    "    try:\n",
    "        rq = requests.get(f\"https://coronavirus.saude.mg.gov.br{url_pdf_link}\")\n",
    "        pdf_data = pdfplumber.open(BytesIO(rq.content))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    # Extracting data\n",
    "    pattern_cases = r'^([0-9]{1,3}\\.[0-9]{3}\\s\\.[0-9]{1,3})|^([0-9]{1,3}\\.[0-9]{3}\\.[0-9]{1,3})|^([0-9]{1,3}\\.[0-9]{1,3})'\n",
    "    pattern_deaths = r'(\\b([0-9]{1,3}\\.[0-9]{3}\\.[0-9]{1,3})\\n|\\b([0-9]{1,3}\\.[0-9]{1,3})\\n|[0-9]{1,2}\\.[0-9]\\s\\s[0-9]{1,3}\\s\\n)'\n",
    "    text = pdf_data.pages[0].extract_text()\n",
    "    total_confirmed = re.search(pattern_cases, text, re.MULTILINE)[0]\n",
    "    total_death = re.search(pattern_deaths, text, re.MULTILINE)[0]\n",
    "    # removing dots and breaklines\n",
    "    total_confirmed = re.sub(r\"\\.|\\n|\\s\", \"\", total_confirmed)\n",
    "    total_death = re.sub(r\"\\.|\\n|\\s\", \"\", total_death)\n",
    "    return [int(total_confirmed), int(total_death)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading excel file from url\n",
    "url = \"https://coronavirus.saude.mg.gov.br/images/microdados/xlsx_painel.xlsx\"\n",
    "file = urllib.request.urlopen(url).read()\n",
    "wb = openpyxl.load_workbook(filename = BytesIO(file), read_only=True)\n",
    "pages = wb.sheetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting cities IBGE code\r\n",
    "with open(\"cod_mun_MG.csv\", mode=\"r\", encoding=\"utf-8\") as fobj:\r\n",
    "    reader = csv.reader(fobj)\r\n",
    "    mun_cod_dict = {str(row[1])[:6]:row[0] for row in reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel file basedo on page returning dict city_code, value and date\n",
    "def excel_data(page):\n",
    "    ws = wb[pages[page]]\n",
    "    data = [list(row) for row in ws.iter_rows(values_only=True)]\n",
    "\n",
    "    headers = [data[0][3], data[0][1], data[0][2]] \n",
    "    values = [[row[3], row[1], row[2]] for row in data[1:]]\n",
    "    \n",
    "    result = []\n",
    "    for value in values:\n",
    "        result.append(dict(zip(headers, value)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dates to generate csv\r\n",
    "dates = [\"2021-04-23\"]\r\n",
    "# Loop to generate based on date\r\n",
    "for date in dates:\r\n",
    "    # Getting total values from pdf\r\n",
    "    total_confirmed_pdf, total_death_pdf = total_values_pdf(\r\n",
    "        \"/\".join(date.split(\"-\")[::-1]))\r\n",
    "\r\n",
    "    date = datetime.datetime.strptime(date, '%Y-%m-%d').date()\r\n",
    "    # Scraping data and generating csv\r\n",
    "    confirmed = excel_data(0)\r\n",
    "    death = excel_data(1)\r\n",
    "    result = []\r\n",
    "    for key, val in mun_cod_dict.items():\r\n",
    "        key = str(key)\r\n",
    "        result.append([val,\r\n",
    "                       sum([item[\"NUM_CASOS\"] for item in confirmed if str(\r\n",
    "                           item[\"CodigoIBGE\"]) == key and item[\"DATA\"].date() <= date]),\r\n",
    "                       sum([item[\"NUM_OBITOS\"] for item in death if str(\r\n",
    "                           item[\"CodigoIBGE\"]) == key and item[\"DATA\"].date() <= date])\r\n",
    "                       ])\r\n",
    "    # Generating csv\r\n",
    "    output_file = f\"MG_{date}.csv\"\r\n",
    "    with open(output_file, mode=\"w\", encoding=\"utf-8\", newline=\"\") as fobj:\r\n",
    "        writer = csv.DictWriter(\r\n",
    "            fobj, fieldnames=[\"municipio\", \"confirmados\", \"mortes\"])\r\n",
    "        writer.writeheader()\r\n",
    "\r\n",
    "        confirmed_total = 0\r\n",
    "        death_total = 0\r\n",
    "        mun_result = []\r\n",
    "        for municipio in result:\r\n",
    "            confirmed_total += int(municipio[1])\r\n",
    "            death_total += int(municipio[2])\r\n",
    "            mun_result.append(\r\n",
    "                {\r\n",
    "                    \"municipio\": municipio[0],\r\n",
    "                    \"confirmados\": municipio[1],\r\n",
    "                    \"mortes\": municipio[2],\r\n",
    "                }\r\n",
    "            )\r\n",
    "        # Importados e Indeninidos\r\n",
    "        imp_ind_confirmed = sum(\r\n",
    "            [item[\"NUM_CASOS\"] for item in confirmed if item[\"CodigoIBGE\"] == None and item[\"DATA\"].date() <= date])\r\n",
    "        imp_ind_deaths = sum(\r\n",
    "            [item[\"NUM_OBITOS\"] for item in death if item[\"CodigoIBGE\"] == None and item[\"DATA\"].date() <= date])\r\n",
    "\r\n",
    "        if total_confirmed_pdf == confirmed_total + imp_ind_confirmed:\r\n",
    "            confirmed_total = total_confirmed_pdf\r\n",
    "        else:\r\n",
    "            print(\"Fail\", output_file,\r\n",
    "                  \"Comparação valores de confirmados apresentou resultados diferentes\")\r\n",
    "            confirmed_total = 0\r\n",
    "        if total_death_pdf == death_total + imp_ind_deaths:\r\n",
    "            death_total = total_death_pdf\r\n",
    "        else:\r\n",
    "            print(\"Fail\", output_file,\r\n",
    "                  \"Comparação valores de mortes apresentou resultados diferentes\")\r\n",
    "            death_total = 0\r\n",
    "        writer.writerows(mun_result)\r\n",
    "        writer.writerow(\r\n",
    "            {\r\n",
    "                \"municipio\": \"Importados/Indefinidos\",\r\n",
    "                \"confirmados\": imp_ind_confirmed,\r\n",
    "                \"mortes\": imp_ind_deaths\r\n",
    "            }\r\n",
    "        )\r\n",
    "        writer.writerow(\r\n",
    "            {\r\n",
    "                \"municipio\": \"TOTAL NO ESTADO\",\r\n",
    "                \"confirmados\": confirmed_total,\r\n",
    "                \"mortes\": death_total,\r\n",
    "            }\r\n",
    "        )\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "name": "python388jvsc74a57bd09bcfbcb8ab2cb80a481072a3cca9f0f9f1b765920b23f0e202d2d845decbede7"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "0c2e7e3db583b5d09671684abc967ad2a40654044959b8f4c9cc6fea5ac782e4"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}