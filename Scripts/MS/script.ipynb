{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot, re, requests, pdfplumber\r\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_values_pdf(url):\r\n",
    "    try:\r\n",
    "        rq = requests.get(url)\r\n",
    "        pdf_data = pdfplumber.open(BytesIO(rq.content))\r\n",
    "    except Exception as e:\r\n",
    "        print(e)\r\n",
    "\r\n",
    "    pattern_cases = r'[0-9]{3}%\\s([\\d]{3}\\.[\\d]{3})'\r\n",
    "    pattern_deaths = r'^([\\d]{1,3}\\.[\\d]{3})\\s[\\d]{1,3}\\,[\\d]{1,2}%'\r\n",
    "\r\n",
    "    # Extracting data\r\n",
    "    text = pdf_data.pages[0].extract_text()\r\n",
    "    total_confirmed = re.search(pattern_cases, text, re.MULTILINE)[0].split(\" \")[1]\r\n",
    "    total_death = re.search(pattern_deaths, text, re.MULTILINE)[0].split(\" \")[0]\r\n",
    "    \r\n",
    "    # Removing dots and breaklines\r\n",
    "    total_confirmed = re.sub(r\"\\.|\\n|\\s\", \"\", total_confirmed)\r\n",
    "    total_death = re.sub(r\"\\.|\\n|\\s\", \"\", total_death)\r\n",
    "    \r\n",
    "    return [int(total_confirmed), int(total_death)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_tables(url):\r\n",
    "    tables = camelot.read_pdf(url, pages=\"all\", strip_text=\"▼, ▲, \\n\")\r\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_row(data_frame, name_row, t_confirmado, t_obito):\n",
    "    data_frame.loc[-1] = [name_row, t_confirmado, t_obito]  # adding a row\n",
    "    data_frame.index = data_frame.index + 1  # shifting index\n",
    "    return data_frame.sort_index()  # sorting by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"https://www.vs.saude.ms.gov.br/wp-content/uploads\"\r\n",
    "dates = [\"2021-05-01\"]\r\n",
    "for date in dates:\r\n",
    "\r\n",
    "    url = f\"{url_base}/{date[:4]}/{date[5:7]}/Boletim-Epidemiologico-COVID-19-{date[:4]}.{date[5:7]}.{date[8:]}.pdf\"\r\n",
    "\r\n",
    "    tables = pdf_tables(url)\r\n",
    "\r\n",
    "    first_line = \"MunicípioÓbitosDistribuiçãoLetalidadeMortalidade\"\r\n",
    "    for table in tables:\r\n",
    "        try:\r\n",
    "            if table.df.at[0, 2] == \"Casosconfirmados\":\r\n",
    "                table.df = table.df.filter([0, 2])\r\n",
    "                table.df.drop([0], inplace=True)\r\n",
    "                # Creat and appending table\r\n",
    "                if not ('data_frame_confirmed' in vars() or 'data_frame_confirmed' in globals()):\r\n",
    "                    data_frame_confirmed = table.df\r\n",
    "                else:\r\n",
    "                    data_frame_confirmed = data_frame_confirmed.append(\r\n",
    "                        table.df, ignore_index=True)\r\n",
    "\r\n",
    "            elif table.df.at[0, 0] == first_line or table.df.at[0, 1] == first_line or table.df.at[0, 2] == first_line:\r\n",
    "                table.df.drop(columns=[0, 4, 5, 6], inplace=True)\r\n",
    "\r\n",
    "                table.df = table.df.drop([0]).reset_index()\r\n",
    "\r\n",
    "                # Rows format\r\n",
    "                for i in range(len(table.df[2])):\r\n",
    "                    if table.df.at[i, 1] != \"=\" and table.df.at[i, 1] != \"\":\r\n",
    "                        table.df.at[i, 2] = \"\".join(\r\n",
    "                            i for i in table.df.at[i, 1] if not i.isdigit())\r\n",
    "\r\n",
    "                # Creat and appending table\r\n",
    "                if not ('data_frame' in vars() or 'data_frame' in globals()):\r\n",
    "                    data_frame = table.df\r\n",
    "                else:\r\n",
    "                    data_frame = data_frame.append(table.df, ignore_index=True)\r\n",
    "\r\n",
    "                data_frame.drop(columns=[1, \"index\"], inplace=True)\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "\r\n",
    "    data_frame_confirmed = data_frame_confirmed.sort_values(by=0)\r\n",
    "    data_frame_confirmed.reset_index(drop=True, inplace=True)\r\n",
    "\r\n",
    "    confirmed_col = data_frame_confirmed[2]\r\n",
    "\r\n",
    "    # Drop first row\r\n",
    "    data_frame = data_frame.drop([0]).reset_index(drop=True)\r\n",
    "\r\n",
    "    data_frame.rename(columns={2: \"municipio\", 3: \"mortes\"}, inplace=True)\r\n",
    "    data_frame.sort_values(by=\"municipio\", inplace=True)\r\n",
    "    data_frame.reset_index(drop=True, inplace=True)\r\n",
    "\r\n",
    "    # Inserting column at the\r\n",
    "    # beginning in the DataFrame\r\n",
    "    data_frame.insert(loc=1,\r\n",
    "                      column='confirmados',\r\n",
    "                      value=confirmed_col)\r\n",
    "\r\n",
    "    data_frame.reset_index(drop=True, inplace=True)\r\n",
    "\r\n",
    "    # Adding space before every uppercase letter\r\n",
    "    data_frame[\"municipio\"] = data_frame[\"municipio\"].apply(\r\n",
    "        lambda x: re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", x))\r\n",
    "    # Adding space before every word + do + de + da\r\n",
    "    data_frame[\"municipio\"] = data_frame[\"municipio\"].apply(\r\n",
    "        lambda x: re.sub(r\"(\\w)((d)(\\w)\\s[A-Z])\", r\"\\1 \\2\", x))\r\n",
    "    # Removing dots from numbers\r\n",
    "    data_frame[\"confirmados\"] = data_frame[\"confirmados\"].apply(\r\n",
    "        lambda x: re.sub(r\"(\\.)\", \"\", x))\r\n",
    "    # Removing dots from numbers\r\n",
    "    data_frame[\"mortes\"] = data_frame[\"mortes\"].apply(\r\n",
    "        lambda x: re.sub(r\"(\\.)\", \"\", x))\r\n",
    "\r\n",
    "    # Remove accents\r\n",
    "    data_frame[\"new\"] = data_frame[\"municipio\"].str.normalize('NFKD')\\\r\n",
    "        .str.encode('ascii', errors='ignore')\\\r\n",
    "        .str.decode('utf-8')\r\n",
    "\r\n",
    "    # Sort by new column, then drop\r\n",
    "    data_frame = data_frame.sort_values(\"new\", ascending=True)\\\r\n",
    "        .drop(\"new\", axis=1)\r\n",
    "\r\n",
    "    data_frame = add_new_row(data_frame, \"Importados/Indefinidos\", 0, 0)\r\n",
    "\r\n",
    "    t_confirmed_fpage, t_deaths_fpage = total_values_pdf(url)\r\n",
    "\r\n",
    "    t_confirmed = data_frame[\"confirmados\"].astype(int).sum()\r\n",
    "    t_deaths = data_frame[\"mortes\"].astype(int).sum()\r\n",
    "\r\n",
    "    if t_confirmed == t_confirmed_fpage and t_deaths == t_deaths_fpage:\r\n",
    "        data_frame = add_new_row(data_frame,\r\n",
    "                                 \"TOTAL NO ESTADO\",\r\n",
    "                                 t_confirmed,\r\n",
    "                                 t_deaths)\r\n",
    "    else:\r\n",
    "        if t_deaths != t_deaths_fpage:    \r\n",
    "            print(\"Contagem de mortes diverge\", t_deaths, t_deaths_fpage)\r\n",
    "        if t_confirmed != t_confirmed_fpage:\r\n",
    "            print(\"Contagem de confirmados diverge\", t_deaths, t_deaths_fpage)\r\n",
    "\r\n",
    "    # Generating csv\r\n",
    "    data_frame.to_csv(f\"MS_{date}.csv\", line_terminator=None, index=False)\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8  ('webscreaping_venv': venv)",
   "name": "pythonjvsc74a57bd01c3b4f3a3e2c3e8780cfee43d81b915f3aa66dace7bef9eda32c5a7dd9110afb"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "1c3b4f3a3e2c3e8780cfee43d81b915f3aa66dace7bef9eda32c5a7dd9110afb"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}